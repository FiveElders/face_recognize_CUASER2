# -*- coding: utf-8 -*-
"""face_recognize_CUASER2

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qJKwSj5C2wSBo8rZ8GgJ9lk18FVcDy1K
"""

!pip install kaggle

!mkdir -p ~/.kaggle
!cp /content/kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d ibrmosal/CUASER2

# 5. فك الضغط (إذا كان الملف مضغوطًا)
!unzip CUASER2.zip -d data/

!kaggle datasets download -d ibrmosal/datasmalldata

# 5. فك الضغط (إذا كان الملف مضغوطًا)
!unzip datasmalldata.zip -d data3/

import zipfile
with zipfile.ZipFile('/content/qyserafteradd.zip', 'r') as zip_ref:
     zip_ref.extractall()

import zipfile
with zipfile.ZipFile('/content/3.zip', 'r') as zip_ref:
     zip_ref.extractall()

!pip install insightface
!pip install onnxruntime

from insightface.app import FaceAnalysis

# Initialize FaceAnalysis with 'detection' in allowed_modules
app = FaceAnalysis(allowed_modules=['detection', 'recognition'], nms=0.4)
app.prepare(ctx_id=0, det_size=(640, 640))

import cv2
# قراءة الصورة
img = cv2.imread('/content/143238232.png')

# الكشف عن الوجوه
faces = app.get(img)

# تعيين عتبة الكشف المطلوبة
threshold = 0.1

# تصفية الوجوه التي تحقق درجة الثقة المطلوبة
filtered_faces = [face for face in faces if face.det_score > threshold]

if len(filtered_faces) > 0:
    # التعامل مع الوجوه المكتشفة بعد التصفية
    face = filtered_faces[0]
    embedding = face.embedding
    # المتابعة في باقي عمليات التعرف أو المعالجة
else:
    print("لم يتم العثور على وجوه تحقق العتبة المطلوبة.")

import cv2
import numpy as np
import insightface
from insightface.app import FaceAnalysis

# تحميل نموذج InsightFace
app = FaceAnalysis(name="buffalo_l")
app.prepare(ctx_id=0, det_size=(640, 640))

# تحميل الصورة
image_path = "/content/results/photo_2025-01-29_22-03-182.jpg"
img = cv2.imread(image_path)

# كشف الوجه
faces = app.get(img)

# تطبيق FFHQ Alignment
for face in faces:
    aligned_face = face.normed_embedding  # المحاذاة التلقائية

    # حفظ الصورة
    cv2.imwrite("aligned_face.jpg", aligned_face * 255)

print("✅ تم حفظ الصورة المحاذاة!")

# import insightface
# from insightface.app import FaceAnalysis
# import cv2
# import numpy as np
# import os

# # تحميل النموذج
# # Pass nms during initialization
# app = FaceAnalysis(allowed_modules=['detection', 'recognition'], nms=0.4)
# app.prepare(ctx_id=0)  # ctx_id=0 تعني استخدام GPU

# # مسار الصور
# dataset_path = "/content/1"
# image_embeddings = {}

# # استخراج Embeddings من مجموعة الصور
# for filename in os.listdir(dataset_path):
#     if filename.endswith(".jpg") or filename.endswith(".png"):
#         img_path = os.path.join(dataset_path, filename)
#         img = cv2.imread(img_path)

#         # اكتشاف الوجه واستخراج الـ Embedding
#         faces = app.get(img)
#         if len(faces) > 0:
#             embedding = faces[0].embedding
#             image_embeddings[filename] = embedding  # حفظ الـ Embedding مع اسم الصورة


# import pickle

# # Save embeddings to a file
# with open("embeddings_amiricapres.pkl", "wb") as f:
#     pickle.dump(image_embeddings, f)

###############FACE AND DETECT AND DROW SQUAR
import cv2
import insightface
from insightface.app import FaceAnalysis
from google.colab.patches import cv2_imshow
# تحميل النموذج
app = FaceAnalysis(allowed_modules=['detection'], nms=0.4)
app.prepare(ctx_id=0)  # ctx_id=0 تعني استخدام GPU (إذا كان متاحًا)

# تحميل الصورة
image_path = "/content/AMEEN ALGAMALEH.jpg"
img = cv2.imread(image_path)

# اكتشاف الوجوه
faces = app.get(img)

# عرض النتائج
for face in faces:
    print(f"تعرفنا على وجه! (منسق الوجه: {face.bbox})")
    # يمكنك رسم مربع حول الوجه المكتشف
    bbox = face.bbox  # إحداثيات مستطيل الوجه (x1, y1, x2, y2)
    cv2.rectangle(img, (int(bbox[0]), int(bbox[1])), (int(bbox[2]), int(bbox[3])), (0, 255, 0), 2)

# عرض الصورة مع المستطيل حول الوجه
cv2_imshow( img)
cv2.waitKey(0)
cv2.destroyAllWindows()

import os
from tqdm import tqdm
import cv2
import numpy as np
import pickle
from insightface.app import FaceAnalysis

# تحميل النموذج
app = FaceAnalysis(allowed_modules=['detection', 'recognition'], nms=0.4)
app.prepare(ctx_id=0)  # ctx_id=0 تعني استخدام GPU

# مسار الصور
dataset_path = "/content/data/2"
image_embeddings = {}

# استخراج Embeddings من مجموعة الصور مع شريط التقدم
image_files = [f for f in os.listdir(dataset_path) if f.endswith(".jpg") or f.endswith(".png")]

# شريط التقدم
for filename in tqdm(image_files, desc="Processing Images", unit="image"):
    img_path = os.path.join(dataset_path, filename)
    img = cv2.imread(img_path)

    # اكتشاف الوجه واستخراج الـ Embedding
    faces = app.get(img)
    if len(faces) > 0:
        embedding = faces[0].embedding
        image_embeddings[filename] = embedding  # حفظ الـ Embedding مع اسم الصورة

# حفظ الـ Embeddings في ملف
with open("finalcayser.pkl", "wb") as f:
    pickle.dump(image_embeddings, f)

import os
from tqdm import tqdm
import cv2
import numpy as np
import pickle
from insightface.app import FaceAnalysis

app = FaceAnalysis(allowed_modules=['detection', 'recognition'], nms=0.4)
app.prepare(ctx_id=0)  # ctx_id=0 تعني استخدام GPU

with open("/content/finalcayser.pkl", "rb") as f:
    image_embeddings = pickle.load(f)

!pip install ImageHash

import os
import shutil
from PIL import Image
import imagehash
from tqdm import tqdm

def collect_unique_images(folder1, folder2, output_folder):
    hashes = set()  # لتخزين الهاشات الفريدة
    os.makedirs(output_folder, exist_ok=True)  # إنشاء المجلد إذا لم يكن موجودًا

    def process_folder(folder):
        """ فحص المجلد وإضافة الصور الفريدة إلى المجلد النهائي """
        files = [os.path.join(root, file) for root, _, files in os.walk(folder) for file in files]
        for path in tqdm(files, desc=f"🔍 فحص {folder}"):
            try:
                img = Image.open(path).convert('RGB')  # فتح الصورة
                h = imagehash.average_hash(img)  # حساب الهاش
                if h not in hashes:  # إذا لم تكن الصورة مكررة
                    hashes.add(h)  # تخزين الهاش
                    shutil.copy(path, os.path.join(output_folder, os.path.basename(path)))  # نسخ الصورة
            except Exception as e:
                print(f"❌ خطأ في فتح الصورة {path}: {e}")

    # معالجة المجلدين
    process_folder(folder1)
    process_folder(folder2)

    # حساب عدد الصور في المجلد الجديد
    num_unique_images = len(os.listdir(output_folder))

    # ضغط المجلد إلى ملف ZIP
    zip_path = shutil.make_archive(output_folder, 'zip', output_folder)

    # عرض النتائج
    print(f"✅ عدد الصور الفريدة: {num_unique_images}")
    print(f"✅ تم حفظ الصور في: {zip_path}")

# المسارات إلى المجلدات
folder1 = "/content/data/2"
folder2 = "/content/data3/1"
output_folder = "/content/unique_images"

# تشغيل الكود
collect_unique_images(folder1, folder2, output_folder)

from scipy.spatial.distance import cosine
import cv2
from google.colab.patches import cv2_imshow
import numpy as np
import os
from insightface.app import FaceAnalysis

# إعداد النموذج
app = FaceAnalysis(name="buffalo_l", providers=['CPUExecutionProvider'])
app.prepare(ctx_id=0, det_size=(640, 640))

dataset_path = "/content/data/2"
top_n_matches = 5  # عدد الصور الأقرب التي تريد عرضها

def compare_faces(input_image_paths, image_embeddings, top_n=top_n_matches):
    all_embeddings = []  # قائمة لتخزين جميع الميزات

    for input_path in input_image_paths:
        input_img = cv2.imread(input_path)
        if input_img is None:
            print(f"❌ لم يتم العثور على الصورة: {input_path}")
            continue

        faces_input = app.get(input_img)
        if len(faces_input) > 0:
            all_embeddings.append(faces_input[0].embedding)
        else:
            print(f"⚠️ لم يتم العثور على وجه في الصورة: {input_path}")

    # التحقق من وجود ميزات مستخرجة
    if len(all_embeddings) == 0:
        print("❌ لم يتم العثور على أي وجه في جميع الصور المدخلة.")
        return

    # حساب المتوسط لجميع الـ Embeddings المستخرجة
    avg_embedding = np.mean(all_embeddings, axis=0)

    distances = []

    # مقارنة الـ Embedding المتوسط مع الصور المخزنة
    for filename, stored_embedding in image_embeddings.items():
        distance = cosine(avg_embedding, stored_embedding)
        distances.append((filename, distance))

    # ترتيب النتائج بناءً على المسافة (أقل مسافة هي الأقرب)
    distances.sort(key=lambda x: x[1])

    # ضبط العدد بحيث لا يتجاوز عدد الصور المخزنة
    top_n = min(len(distances), top_n)

    # عرض أقرب N صور
    print(f"\n🎯 أقرب {top_n} صور بناءً على المتوسط:")
    for i, (best_match, best_distance) in enumerate(distances[:top_n]):
        similarity = (1 - best_distance) * 100
        print(f"🔹 الصورة {i + 1}: {best_match} (المسافة: {best_distance:.4f}, نسبة التشابه: {similarity:.2f}%)")

        matched_img_path = os.path.join(dataset_path, best_match)
        matched_img = cv2.imread(matched_img_path)
        cv2_imshow(matched_img)

# اختبار الكود مع صور متعددة
input_images = ["/content/photo_٢٠٢٥-٠٣-٠٤_١٦-٥٥-٠٢.jpg"]
compare_faces(input_images, image_embeddings, top_n=20)  # يمكنك تغيير الرقم هنا

!pip install deepface

from deepface import DeepFace
import cv2
import numpy as np
import os
from insightface.app import FaceAnalysis
# تحميل الصور
image1_path = "/content/gettyimages-161674323-612x612.jpg"  # ضع مسار الصورة الأولى هنا
image2_path = "/content/gettyimages-1946327481-612x612.jpg"  # ضع مسار الصورة الثانية هنا

# ================== 📌 مقارنة باستخدام DeepFace ==================
result_deepface = DeepFace.verify(image1_path, image2_path, model_name="VGG-Face", enforce_detection=False)

# حساب نسبة التشابه من DeepFace (مبنية على المسافة)
similarity_deepface = (1 - result_deepface["distance"]) * 100
similarity_deepface = max(0, min(similarity_deepface, 100))  # ضمان أن تكون النسبة بين 0% و 100%

# ================== 📌 مقارنة باستخدام InsightFace ==================
# تحميل نموذج تحليل الوجه
# app = FaceAnalysis(allowed_modules=['detection', 'recognition'], nms=0.4)
# app.prepare(ctx_id=0)  # ctx_id=0 تعني استخدام GPU

# # تحميل الصور وقراءتها
# img1 = cv2.imread(image1_path)
# img2 = cv2.imread(image2_path)

# # استخراج ميزات الوجه من الصور
# faces1 = app.get(img1)
# faces2 = app.get(img2)

# if len(faces1) == 0 or len(faces2) == 0:
#     print("⚠️ لم يتم العثور على وجه في إحدى الصور.")
#     similarity_insightface = 0
# else:
#     embedding1 = faces1[0].embedding  # استخراج الـ embedding للصورة الأولى
#     embedding2 = faces2[0].embedding  # استخراج الـ embedding للصورة الثانية

#     # حساب تشابه Cosine بين الوجهين
#     distance = cosine(embedding1, embedding2)  # حساب المسافة الكوزينية
#     similarity_insightface = (1 - distance) * 100  # تحويلها إلى نسبة مئوية

# ================== 📌 طباعة النتائج ==================
print("🔍 **نتائج مقارنة الوجه:**")
print(f"✅ نسبة التشابه باستخدام **DeepFace**: {similarity_deepface:.2f}%")
# print(f"✅ نسبة التشابه باستخدام **InsightFace (ArcFace)**: {similarity_insightface:.2f}%")

import os
import pickle
from tqdm import tqdm
from deepface import DeepFace
import numpy as np

# # استخراج الميزات من فولدر وتخزينها في ملف pkl
def extract_features_from_folder(folder_path, output_file):
    feature_dict = {}
    for image_name in tqdm(os.listdir(folder_path), desc="Extracting features"):
        image_path = os.path.join(folder_path, image_name)
        try:
            result = DeepFace.represent(image_path, model_name="VGG-Face", enforce_detection=False)
            # Store only the embedding vector
            feature_dict[image_name] = np.array(result[0]["embedding"])
        except Exception as e:
            print(f"Error processing {image_name}: {e}")

    with open(output_file, 'wb') as f:
        pickle.dump(feature_dict, f)

# مثال على الاستخدام
folder_path = "/content/data/2"  # استبدلها بمسار المجلد
output_file = "/content/features3.pkl"  # ملف pkl الذي سيحتوي على الميزات

# استخراج الميزات وحفظها
extract_features_from_folder(folder_path, output_file)

import cv2
import os
import numpy as np
from google.colab.patches import cv2_imshow  # استخدم cv2.imshow إذا كنت تعمل محليًا
def compare_image(input_image_path, feature_file, top_n=3):
    with open(feature_file, 'rb') as f:
        feature_dict = pickle.load(f)

    # استخراج ميزات الصورة المدخلة
    input_feature = DeepFace.represent(input_image_path, model_name="VGG-Face", enforce_detection=False)[0]["embedding"]

    distances = []

    # مقارنة الميزات وحساب المسافات
    for image_name, stored_feature in feature_dict.items():
        distance = np.linalg.norm(np.array(input_feature) - np.array(stored_feature))
        distances.append((image_name, distance))

    # ترتيب الصور حسب المسافة
    distances.sort(key=lambda x: x[1])

    # استخراج أقرب top_n صور
    closest_images = distances[:top_n]

    return closest_images
def compare_and_display(input_image_path, feature_file, dataset_path, top_n=3):
    # استدعاء الدالة لحساب أقرب الصور
    closest_images = compare_image(input_image_path, feature_file, top_n)

    print("📸 أقرب 3 صور هي:")

    # تحميل الصورة المدخلة
    input_img = cv2.imread(input_image_path)

    # حساب أقصى مسافة لتطبيع نسبة التشابه
    max_distance = max([dist for _, dist in closest_images]) if closest_images else 1

    for i, (image_name, distance) in enumerate(closest_images):
        # حساب نسبة التشابه بناءً على المسافة
        similarity_deepface = (1 - (distance / max_distance)) * 100 if max_distance > 0 else 100
        similarity_deepface = max(0, min(similarity_deepface, 100))  # التأكد أن النسبة بين 0% و 100%

        # طباعة نسبة التشابه
        print(f"🔹 الصورة {i+1}: {image_name} | المسافة: {distance:.4f} | نسبة التشابه: {similarity_deepface:.2f}%")

        # تحميل الصورة المطابقة
        matched_img_path = os.path.join(dataset_path, image_name)
        matched_img = cv2.imread(matched_img_path)

        if matched_img is not None:
            # عرض نسبة التشابه ثم الصورة المطابقة
            print(f"🔸 نسبة التشابه للصورة {i+1}: {similarity_deepface:.2f}%")
            cv2_imshow(matched_img)  # عرض الصورة
            print("")  # سطر فارغ بين الصور للمزيد من الوضوح

def display_images(input_img, matched_images):
    """عرض الصورة المدخلة بجانب الصور المطابقة مع نسبة التشابه"""
    if not matched_images:
        print("❌ لم يتم العثور على صور متطابقة!")
        return

    # تغيير حجم الصورة المدخلة لتتناسب مع الصور الأخرى
    w = matched_images[0][0].shape[1]  # أخذ عرض الصورة الأولى
    h = matched_images[0][0].shape[0]  # أخذ ارتفاع الصورة الأولى
    input_resized = cv2.resize(input_img, (w, h))

    # دمج الصور عموديًا مع تغيير الحجم لتتناسب مع نفس العرض
    combined_img = [input_resized] + [cv2.resize(img, (w, h)) for img, _ in matched_images]
    final_image = cv2.vconcat(combined_img)  # دمج الصور عموديًا

    # عرض الصور عموديًا
    cv2_imshow(final_image)

    # طباعة نسبة التشابه أسفل كل صورة
    for i, (_, similarity) in enumerate(matched_images):
        print(f"🔹 صورة {i+1}: نسبة التشابه {similarity:.2f}%")

# بعد رفع صورة جديدة، يمكنك مقارنة الصورة مع الميزات المخزنة واستخراج أقرب 3 صور
# input_image_path = "/content/gettyimages-1437589921-612x612.jpg"  # استبدلها بالصورة التي ترغب في مقارنتها
# closest_images = compare_image(input_image_path, output_file)

# print("The closest 3 images are:")
# for image_name, distance in closest_images:
#     print(f"{image_name} with distance: {distance}")
output_file = "/content/features2.pkl"
input_image_path = "/content/photo_2025-01-31_12-02-05.jpg"  # استبدلها بالصورة المدخلة
dataset_path = "/content/data/2"  # مسار الداتا ست الخاصة بك
compare_and_display(input_image_path, output_file, dataset_path)

#########################################optimize model for extract two images

import pickle

# Load the embeddings file
file_path = "/content/features2.pkl"

def count_vectors(file_path):
    try:
        with open(file_path, "rb") as f:
            embeddings = pickle.load(f)  # Load the embeddings dictionary

        # Count the number of vectors
        vector_count = len(embeddings)
        print(f"Number of vectors in the file: {vector_count}")
    except Exception as e:
        print(f"An error occurred: {e}")

# Call the function
count_vectors(file_path)

# from scipy.spatial.distance import cosine
# import cv2
# from google.colab.patches import cv2_imshow

# dataset_path = "/content/2"
# def compare_face(input_image_path):
#     # تحميل الصورة المدخلة
#     input_img = cv2.imread(input_image_path)
#     faces_input = app.get(input_img)

#     if len(faces_input) > 0:
#         input_embedding = faces_input[0].embedding  # استخراج الـ Embedding للصورة المدخلة

#         best_match = None
#         best_distance = float("inf")

#         # مقارنة الـ Embedding المدخل مع جميع الـ Embeddings المخزنة
#         for filename, stored_embedding in image_embeddings.items():
#             distance = cosine(input_embedding, stored_embedding)

#             if distance < best_distance:
#                 best_distance = distance
#                 best_match = filename

#         # إذا كانت المسافة أقل من حد معين (مثلاً 0.6)، فإن الوجه متطابق
#         if best_distance :#< 0.6
#             similarity = (1 - best_distance) * 100  # نسبة التشابه (بالنسبة المئوية)
#             print(f"الشخص موجود في الصورة: {best_match} (المسافة: {best_distance}, نسبة التشابه: {similarity:.2f}%)")

#             # عرض الصورة المطابقة والصورة المدخلة جنبًا إلى جنب
#             matched_img_path = f"{dataset_path}/{best_match}"
#             matched_img = cv2.imread(matched_img_path)

#             # تغيير حجم الصور لتكون بنفس الأبعاد
#             input_img = cv2.resize(input_img, (matched_img.shape[1], matched_img.shape[0]))

#             combined_img = cv2.hconcat([input_img, matched_img])

#             # عرض الصور جنبًا إلى جنب
#             cv2_imshow(combined_img)
#             cv2.waitKey(0)
#             cv2.destroyAllWindows()
#         else:
#             print("لم يتم العثور على تطابق.")
#     else:
#         print("لم يتم العثور على وجه في الصورة المدخلة.")

# # اختبار الدالة مع صورة جديدة
# compare_face("/content/436x328_97938_197934.jpg")

import insightface
from insightface.app import FaceAnalysis
import cv2
import numpy as np

# تحميل النموذج
# Include the 'landmark_3d_68' module during initialization
app = FaceAnalysis(allowed_modules=['detection', 'recognition', 'landmark_3d_68'], nms=0.4)
app.prepare(ctx_id=0)

# تحميل صورة الوجه
image_path = "/content/gettyimages-578551318-612x612.jpg"
img = cv2.imread(image_path)

# اكتشاف الوجه واستخراج المعالم
faces = app.get(img)

if len(faces) > 0:
    face = faces[0]

    # استخراج المعالم ثلاثية الأبعاد وثنائية الأبعاد
    landmark_3d = face.landmark_3d_68
    landmark_2d = face.landmark_2d_106

    # Check if landmark_3d is not None before iterating
    if landmark_3d is not None:
        # رسم المعالم ثلاثية الأبعاد باللون الأزرق
        for point in landmark_3d:
            x, y, z = int(point[0]), int(point[1]), point[2]
            cv2.circle(img, (x, y), 2, (255, 0, 0), -1)
    else:
        print("3D Landmarks not detected.")

    # Check if landmark_2d is not None before iterating
    if landmark_2d is not None:
        # رسم آخر 2 من المعالم ثنائية الأبعاد باللون الأخضر
        for point in landmark_2d[-2:]:
            x, y = int(point[0]), int(point[1])
            cv2.circle(img, (x, y), 3, (0, 255, 0), -1)
    else:
        print("2D Landmarks not detected.")

    # عرض الصورة مع المعالم
    cv2_imshow(img)
    cv2.waitKey(0)
    cv2.destroyAllWindows()

else:
    print("لم يتم العثور على وجه في الصورة.")

import insightface
from insightface.app import FaceAnalysis
import cv2
import numpy as np
from scipy.spatial.distance import cosine
import os

# تحميل النموذج مع دعم المعالم ثلاثية الأبعاد
app = FaceAnalysis(allowed_modules=['detection', 'recognition', 'landmark_3d_68'], nms=0.4)
app.prepare(ctx_id=0)  # ctx_id=0 تعني استخدام GPU إذا كان متوفرًا

# مسار الصور
dataset_path = "/content/3"  # ضع مسار مجموعة الصور هنا
image_embeddings = {}

# استخراج المميزات (features) من مجموعة الصور
for filename in os.listdir(dataset_path):
    if filename.endswith(".jpg") or filename.endswith(".png"):
        img_path = os.path.join(dataset_path, filename)
        img = cv2.imread(img_path)
        faces = app.get(img)

        if len(faces) > 0:
            face = faces[0]
            embedding = face.embedding  # استخراج الميزة (feature) للوجه
            landmark_3d = face.landmark_3d_68
            landmark_2d = face.landmark_2d_106

            # حفظ الميزة والمعالم باسم الصورة
            image_embeddings[filename] = {
                "embedding": embedding,
                "landmark_3d": landmark_3d,
                "landmark_2d": landmark_2d,
            }
print("تم استخراج الميزات من مجموعة الصور.")

# دالة لمقارنة الصورة المدخلة
def compare_face(input_image_path):
    # تحميل الصورة المدخلة
    input_img = cv2.imread(input_image_path)
    faces_input = app.get(input_img)

    if len(faces_input) > 0:
        face_input = faces_input[0]
        input_embedding = face_input.embedding  # استخراج الميزة للصورة المدخلة
        input_landmark_3d = face_input.landmark_3d_68
        input_landmark_2d = face_input.landmark_2d_106

        best_match = None
        best_distance = float("inf")

        # مقارنة الميزة المدخلة مع جميع الميزات المخزنة
        for filename, data in image_embeddings.items():
            stored_embedding = data["embedding"]
            distance = cosine(input_embedding, stored_embedding)  # حساب المسافة باستخدام Cosine

            if distance < best_distance:
                best_distance = distance
                best_match = filename

        # عرض النتائج
        if best_distance :  # عتبة التشابه
            similarity = (1 - best_distance) * 100  # نسبة التشابه
            print(f"الصورة المدخلة تشبه الصورة: {best_match} (المسافة: {best_distance:.2f}, نسبة التشابه: {similarity:.2f}%)")

            # عرض الصورة المدخلة والصورة المطابقة
            matched_img_path = os.path.join(dataset_path, best_match)
            matched_img = cv2.imread(matched_img_path)

            # تغيير حجم الصور لتكون بنفس الأبعاد
            input_img_resized = cv2.resize(input_img, (matched_img.shape[1], matched_img.shape[0]))
            combined_img = cv2.hconcat([input_img_resized, matched_img])

            # رسم المعالم ثلاثية الأبعاد (بالأزرق) والمعالم ثنائية الأبعاد (بالأخضر)
            if input_landmark_3d is not None:
                for point in input_landmark_3d:
                    x, y, z = int(point[0]), int(point[1]), point[2]
                    cv2.circle(input_img_resized, (x, y), 2, (255, 0, 0), -1)
            if input_landmark_2d is not None:
                for point in input_landmark_2d[-2:]:
                    x, y = int(point[0]), int(point[1])
                    cv2.circle(input_img_resized, (x, y), 3, (0, 255, 0), -1)

            cv2_imshow( combined_img)
            cv2.waitKey(0)
            cv2.destroyAllWindows()
        else:
            print("لم يتم العثور على تطابق مناسب.")
    else:
        print("لم يتم العثور على وجه في الصورة المدخلة.")

# اختبار الدالة مع صورة جديدة
compare_face("/content/gettyimages-578551318-612x612.jpg")  # ضع مسار الصورة المدخلة هنا