# -*- coding: utf-8 -*-
"""face_recognize_CUASER2

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qJKwSj5C2wSBo8rZ8GgJ9lk18FVcDy1K
"""

!pip install kaggle

!mkdir -p ~/.kaggle
!cp /content/kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d ibrmosal/CUASER2

# 5. ÙÙƒ Ø§Ù„Ø¶ØºØ· (Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù…Ù„Ù Ù…Ø¶ØºÙˆØ·Ù‹Ø§)
!unzip CUASER2.zip -d data/

!kaggle datasets download -d ibrmosal/datasmalldata

# 5. ÙÙƒ Ø§Ù„Ø¶ØºØ· (Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù…Ù„Ù Ù…Ø¶ØºÙˆØ·Ù‹Ø§)
!unzip datasmalldata.zip -d data3/

import zipfile
with zipfile.ZipFile('/content/qyserafteradd.zip', 'r') as zip_ref:
     zip_ref.extractall()

import zipfile
with zipfile.ZipFile('/content/3.zip', 'r') as zip_ref:
     zip_ref.extractall()

!pip install insightface
!pip install onnxruntime

from insightface.app import FaceAnalysis

# Initialize FaceAnalysis with 'detection' in allowed_modules
app = FaceAnalysis(allowed_modules=['detection', 'recognition'], nms=0.4)
app.prepare(ctx_id=0, det_size=(640, 640))

import cv2
# Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„ØµÙˆØ±Ø©
img = cv2.imread('/content/143238232.png')

# Ø§Ù„ÙƒØ´Ù Ø¹Ù† Ø§Ù„ÙˆØ¬ÙˆÙ‡
faces = app.get(img)

# ØªØ¹ÙŠÙŠÙ† Ø¹ØªØ¨Ø© Ø§Ù„ÙƒØ´Ù Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
threshold = 0.1

# ØªØµÙÙŠØ© Ø§Ù„ÙˆØ¬ÙˆÙ‡ Ø§Ù„ØªÙŠ ØªØ­Ù‚Ù‚ Ø¯Ø±Ø¬Ø© Ø§Ù„Ø«Ù‚Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
filtered_faces = [face for face in faces if face.det_score > threshold]

if len(filtered_faces) > 0:
    # Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„ÙˆØ¬ÙˆÙ‡ Ø§Ù„Ù…ÙƒØªØ´ÙØ© Ø¨Ø¹Ø¯ Ø§Ù„ØªØµÙÙŠØ©
    face = filtered_faces[0]
    embedding = face.embedding
    # Ø§Ù„Ù…ØªØ§Ø¨Ø¹Ø© ÙÙŠ Ø¨Ø§Ù‚ÙŠ Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„ØªØ¹Ø±Ù Ø£Ùˆ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
else:
    print("Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ ÙˆØ¬ÙˆÙ‡ ØªØ­Ù‚Ù‚ Ø§Ù„Ø¹ØªØ¨Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©.")

import cv2
import numpy as np
import insightface
from insightface.app import FaceAnalysis

# ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ InsightFace
app = FaceAnalysis(name="buffalo_l")
app.prepare(ctx_id=0, det_size=(640, 640))

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©
image_path = "/content/results/photo_2025-01-29_22-03-182.jpg"
img = cv2.imread(image_path)

# ÙƒØ´Ù Ø§Ù„ÙˆØ¬Ù‡
faces = app.get(img)

# ØªØ·Ø¨ÙŠÙ‚ FFHQ Alignment
for face in faces:
    aligned_face = face.normed_embedding  # Ø§Ù„Ù…Ø­Ø§Ø°Ø§Ø© Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠØ©

    # Ø­ÙØ¸ Ø§Ù„ØµÙˆØ±Ø©
    cv2.imwrite("aligned_face.jpg", aligned_face * 255)

print("âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ø­Ø§Ø°Ø§Ø©!")

# import insightface
# from insightface.app import FaceAnalysis
# import cv2
# import numpy as np
# import os

# # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
# # Pass nms during initialization
# app = FaceAnalysis(allowed_modules=['detection', 'recognition'], nms=0.4)
# app.prepare(ctx_id=0)  # ctx_id=0 ØªØ¹Ù†ÙŠ Ø§Ø³ØªØ®Ø¯Ø§Ù… GPU

# # Ù…Ø³Ø§Ø± Ø§Ù„ØµÙˆØ±
# dataset_path = "/content/1"
# image_embeddings = {}

# # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Embeddings Ù…Ù† Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„ØµÙˆØ±
# for filename in os.listdir(dataset_path):
#     if filename.endswith(".jpg") or filename.endswith(".png"):
#         img_path = os.path.join(dataset_path, filename)
#         img = cv2.imread(img_path)

#         # Ø§ÙƒØªØ´Ø§Ù Ø§Ù„ÙˆØ¬Ù‡ ÙˆØ§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù€ Embedding
#         faces = app.get(img)
#         if len(faces) > 0:
#             embedding = faces[0].embedding
#             image_embeddings[filename] = embedding  # Ø­ÙØ¸ Ø§Ù„Ù€ Embedding Ù…Ø¹ Ø§Ø³Ù… Ø§Ù„ØµÙˆØ±Ø©


# import pickle

# # Save embeddings to a file
# with open("embeddings_amiricapres.pkl", "wb") as f:
#     pickle.dump(image_embeddings, f)

###############FACE AND DETECT AND DROW SQUAR
import cv2
import insightface
from insightface.app import FaceAnalysis
from google.colab.patches import cv2_imshow
# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
app = FaceAnalysis(allowed_modules=['detection'], nms=0.4)
app.prepare(ctx_id=0)  # ctx_id=0 ØªØ¹Ù†ÙŠ Ø§Ø³ØªØ®Ø¯Ø§Ù… GPU (Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…ØªØ§Ø­Ù‹Ø§)

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©
image_path = "/content/AMEEN ALGAMALEH.jpg"
img = cv2.imread(image_path)

# Ø§ÙƒØªØ´Ø§Ù Ø§Ù„ÙˆØ¬ÙˆÙ‡
faces = app.get(img)

# Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
for face in faces:
    print(f"ØªØ¹Ø±ÙÙ†Ø§ Ø¹Ù„Ù‰ ÙˆØ¬Ù‡! (Ù…Ù†Ø³Ù‚ Ø§Ù„ÙˆØ¬Ù‡: {face.bbox})")
    # ÙŠÙ…ÙƒÙ†Ùƒ Ø±Ø³Ù… Ù…Ø±Ø¨Ø¹ Ø­ÙˆÙ„ Ø§Ù„ÙˆØ¬Ù‡ Ø§Ù„Ù…ÙƒØªØ´Ù
    bbox = face.bbox  # Ø¥Ø­Ø¯Ø§Ø«ÙŠØ§Øª Ù…Ø³ØªØ·ÙŠÙ„ Ø§Ù„ÙˆØ¬Ù‡ (x1, y1, x2, y2)
    cv2.rectangle(img, (int(bbox[0]), int(bbox[1])), (int(bbox[2]), int(bbox[3])), (0, 255, 0), 2)

# Ø¹Ø±Ø¶ Ø§Ù„ØµÙˆØ±Ø© Ù…Ø¹ Ø§Ù„Ù…Ø³ØªØ·ÙŠÙ„ Ø­ÙˆÙ„ Ø§Ù„ÙˆØ¬Ù‡
cv2_imshow( img)
cv2.waitKey(0)
cv2.destroyAllWindows()

import os
from tqdm import tqdm
import cv2
import numpy as np
import pickle
from insightface.app import FaceAnalysis

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
app = FaceAnalysis(allowed_modules=['detection', 'recognition'], nms=0.4)
app.prepare(ctx_id=0)  # ctx_id=0 ØªØ¹Ù†ÙŠ Ø§Ø³ØªØ®Ø¯Ø§Ù… GPU

# Ù…Ø³Ø§Ø± Ø§Ù„ØµÙˆØ±
dataset_path = "/content/data/2"
image_embeddings = {}

# Ø§Ø³ØªØ®Ø±Ø§Ø¬ Embeddings Ù…Ù† Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„ØµÙˆØ± Ù…Ø¹ Ø´Ø±ÙŠØ· Ø§Ù„ØªÙ‚Ø¯Ù…
image_files = [f for f in os.listdir(dataset_path) if f.endswith(".jpg") or f.endswith(".png")]

# Ø´Ø±ÙŠØ· Ø§Ù„ØªÙ‚Ø¯Ù…
for filename in tqdm(image_files, desc="Processing Images", unit="image"):
    img_path = os.path.join(dataset_path, filename)
    img = cv2.imread(img_path)

    # Ø§ÙƒØªØ´Ø§Ù Ø§Ù„ÙˆØ¬Ù‡ ÙˆØ§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù€ Embedding
    faces = app.get(img)
    if len(faces) > 0:
        embedding = faces[0].embedding
        image_embeddings[filename] = embedding  # Ø­ÙØ¸ Ø§Ù„Ù€ Embedding Ù…Ø¹ Ø§Ø³Ù… Ø§Ù„ØµÙˆØ±Ø©

# Ø­ÙØ¸ Ø§Ù„Ù€ Embeddings ÙÙŠ Ù…Ù„Ù
with open("finalcayser.pkl", "wb") as f:
    pickle.dump(image_embeddings, f)

import os
from tqdm import tqdm
import cv2
import numpy as np
import pickle
from insightface.app import FaceAnalysis

app = FaceAnalysis(allowed_modules=['detection', 'recognition'], nms=0.4)
app.prepare(ctx_id=0)  # ctx_id=0 ØªØ¹Ù†ÙŠ Ø§Ø³ØªØ®Ø¯Ø§Ù… GPU

with open("/content/finalcayser.pkl", "rb") as f:
    image_embeddings = pickle.load(f)

!pip install ImageHash

import os
import shutil
from PIL import Image
import imagehash
from tqdm import tqdm

def collect_unique_images(folder1, folder2, output_folder):
    hashes = set()  # Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù‡Ø§Ø´Ø§Øª Ø§Ù„ÙØ±ÙŠØ¯Ø©
    os.makedirs(output_folder, exist_ok=True)  # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯Ù‹Ø§

    def process_folder(folder):
        """ ÙØ­Øµ Ø§Ù„Ù…Ø¬Ù„Ø¯ ÙˆØ¥Ø¶Ø§ÙØ© Ø§Ù„ØµÙˆØ± Ø§Ù„ÙØ±ÙŠØ¯Ø© Ø¥Ù„Ù‰ Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ """
        files = [os.path.join(root, file) for root, _, files in os.walk(folder) for file in files]
        for path in tqdm(files, desc=f"ğŸ” ÙØ­Øµ {folder}"):
            try:
                img = Image.open(path).convert('RGB')  # ÙØªØ­ Ø§Ù„ØµÙˆØ±Ø©
                h = imagehash.average_hash(img)  # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù‡Ø§Ø´
                if h not in hashes:  # Ø¥Ø°Ø§ Ù„Ù… ØªÙƒÙ† Ø§Ù„ØµÙˆØ±Ø© Ù…ÙƒØ±Ø±Ø©
                    hashes.add(h)  # ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù‡Ø§Ø´
                    shutil.copy(path, os.path.join(output_folder, os.path.basename(path)))  # Ù†Ø³Ø® Ø§Ù„ØµÙˆØ±Ø©
            except Exception as e:
                print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ÙØªØ­ Ø§Ù„ØµÙˆØ±Ø© {path}: {e}")

    # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø¬Ù„Ø¯ÙŠÙ†
    process_folder(folder1)
    process_folder(folder2)

    # Ø­Ø³Ø§Ø¨ Ø¹Ø¯Ø¯ Ø§Ù„ØµÙˆØ± ÙÙŠ Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø¬Ø¯ÙŠØ¯
    num_unique_images = len(os.listdir(output_folder))

    # Ø¶ØºØ· Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø¥Ù„Ù‰ Ù…Ù„Ù ZIP
    zip_path = shutil.make_archive(output_folder, 'zip', output_folder)

    # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
    print(f"âœ… Ø¹Ø¯Ø¯ Ø§Ù„ØµÙˆØ± Ø§Ù„ÙØ±ÙŠØ¯Ø©: {num_unique_images}")
    print(f"âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„ØµÙˆØ± ÙÙŠ: {zip_path}")

# Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª Ø¥Ù„Ù‰ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª
folder1 = "/content/data/2"
folder2 = "/content/data3/1"
output_folder = "/content/unique_images"

# ØªØ´ØºÙŠÙ„ Ø§Ù„ÙƒÙˆØ¯
collect_unique_images(folder1, folder2, output_folder)

from scipy.spatial.distance import cosine
import cv2
from google.colab.patches import cv2_imshow
import numpy as np
import os
from insightface.app import FaceAnalysis

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
app = FaceAnalysis(name="buffalo_l", providers=['CPUExecutionProvider'])
app.prepare(ctx_id=0, det_size=(640, 640))

dataset_path = "/content/data/2"
top_n_matches = 5  # Ø¹Ø¯Ø¯ Ø§Ù„ØµÙˆØ± Ø§Ù„Ø£Ù‚Ø±Ø¨ Ø§Ù„ØªÙŠ ØªØ±ÙŠØ¯ Ø¹Ø±Ø¶Ù‡Ø§

def compare_faces(input_image_paths, image_embeddings, top_n=top_n_matches):
    all_embeddings = []  # Ù‚Ø§Ø¦Ù…Ø© Ù„ØªØ®Ø²ÙŠÙ† Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ÙŠØ²Ø§Øª

    for input_path in input_image_paths:
        input_img = cv2.imread(input_path)
        if input_img is None:
            print(f"âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„ØµÙˆØ±Ø©: {input_path}")
            continue

        faces_input = app.get(input_img)
        if len(faces_input) > 0:
            all_embeddings.append(faces_input[0].embedding)
        else:
            print(f"âš ï¸ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ ÙˆØ¬Ù‡ ÙÙŠ Ø§Ù„ØµÙˆØ±Ø©: {input_path}")

    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ù…ÙŠØ²Ø§Øª Ù…Ø³ØªØ®Ø±Ø¬Ø©
    if len(all_embeddings) == 0:
        print("âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø£ÙŠ ÙˆØ¬Ù‡ ÙÙŠ Ø¬Ù…ÙŠØ¹ Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…Ø¯Ø®Ù„Ø©.")
        return

    # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…ØªÙˆØ³Ø· Ù„Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù€ Embeddings Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø©
    avg_embedding = np.mean(all_embeddings, axis=0)

    distances = []

    # Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù€ Embedding Ø§Ù„Ù…ØªÙˆØ³Ø· Ù…Ø¹ Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…Ø®Ø²Ù†Ø©
    for filename, stored_embedding in image_embeddings.items():
        distance = cosine(avg_embedding, stored_embedding)
        distances.append((filename, distance))

    # ØªØ±ØªÙŠØ¨ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø³Ø§ÙØ© (Ø£Ù‚Ù„ Ù…Ø³Ø§ÙØ© Ù‡ÙŠ Ø§Ù„Ø£Ù‚Ø±Ø¨)
    distances.sort(key=lambda x: x[1])

    # Ø¶Ø¨Ø· Ø§Ù„Ø¹Ø¯Ø¯ Ø¨Ø­ÙŠØ« Ù„Ø§ ÙŠØªØ¬Ø§ÙˆØ² Ø¹Ø¯Ø¯ Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…Ø®Ø²Ù†Ø©
    top_n = min(len(distances), top_n)

    # Ø¹Ø±Ø¶ Ø£Ù‚Ø±Ø¨ N ØµÙˆØ±
    print(f"\nğŸ¯ Ø£Ù‚Ø±Ø¨ {top_n} ØµÙˆØ± Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù…ØªÙˆØ³Ø·:")
    for i, (best_match, best_distance) in enumerate(distances[:top_n]):
        similarity = (1 - best_distance) * 100
        print(f"ğŸ”¹ Ø§Ù„ØµÙˆØ±Ø© {i + 1}: {best_match} (Ø§Ù„Ù…Ø³Ø§ÙØ©: {best_distance:.4f}, Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ´Ø§Ø¨Ù‡: {similarity:.2f}%)")

        matched_img_path = os.path.join(dataset_path, best_match)
        matched_img = cv2.imread(matched_img_path)
        cv2_imshow(matched_img)

# Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ÙƒÙˆØ¯ Ù…Ø¹ ØµÙˆØ± Ù…ØªØ¹Ø¯Ø¯Ø©
input_images = ["/content/photo_Ù¢Ù Ù¢Ù¥-Ù Ù£-Ù Ù¤_Ù¡Ù¦-Ù¥Ù¥-Ù Ù¢.jpg"]
compare_faces(input_images, image_embeddings, top_n=20)  # ÙŠÙ…ÙƒÙ†Ùƒ ØªØºÙŠÙŠØ± Ø§Ù„Ø±Ù‚Ù… Ù‡Ù†Ø§

!pip install deepface

from deepface import DeepFace
import cv2
import numpy as np
import os
from insightface.app import FaceAnalysis
# ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±
image1_path = "/content/gettyimages-161674323-612x612.jpg"  # Ø¶Ø¹ Ù…Ø³Ø§Ø± Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰ Ù‡Ù†Ø§
image2_path = "/content/gettyimages-1946327481-612x612.jpg"  # Ø¶Ø¹ Ù…Ø³Ø§Ø± Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø«Ø§Ù†ÙŠØ© Ù‡Ù†Ø§

# ================== ğŸ“Œ Ù…Ù‚Ø§Ø±Ù†Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… DeepFace ==================
result_deepface = DeepFace.verify(image1_path, image2_path, model_name="VGG-Face", enforce_detection=False)

# Ø­Ø³Ø§Ø¨ Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ´Ø§Ø¨Ù‡ Ù…Ù† DeepFace (Ù…Ø¨Ù†ÙŠØ© Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø³Ø§ÙØ©)
similarity_deepface = (1 - result_deepface["distance"]) * 100
similarity_deepface = max(0, min(similarity_deepface, 100))  # Ø¶Ù…Ø§Ù† Ø£Ù† ØªÙƒÙˆÙ† Ø§Ù„Ù†Ø³Ø¨Ø© Ø¨ÙŠÙ† 0% Ùˆ 100%

# ================== ğŸ“Œ Ù…Ù‚Ø§Ø±Ù†Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… InsightFace ==================
# ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙˆØ¬Ù‡
# app = FaceAnalysis(allowed_modules=['detection', 'recognition'], nms=0.4)
# app.prepare(ctx_id=0)  # ctx_id=0 ØªØ¹Ù†ÙŠ Ø§Ø³ØªØ®Ø¯Ø§Ù… GPU

# # ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ± ÙˆÙ‚Ø±Ø§Ø¡ØªÙ‡Ø§
# img1 = cv2.imread(image1_path)
# img2 = cv2.imread(image2_path)

# # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ÙŠØ²Ø§Øª Ø§Ù„ÙˆØ¬Ù‡ Ù…Ù† Ø§Ù„ØµÙˆØ±
# faces1 = app.get(img1)
# faces2 = app.get(img2)

# if len(faces1) == 0 or len(faces2) == 0:
#     print("âš ï¸ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ ÙˆØ¬Ù‡ ÙÙŠ Ø¥Ø­Ø¯Ù‰ Ø§Ù„ØµÙˆØ±.")
#     similarity_insightface = 0
# else:
#     embedding1 = faces1[0].embedding  # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù€ embedding Ù„Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰
#     embedding2 = faces2[0].embedding  # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù€ embedding Ù„Ù„ØµÙˆØ±Ø© Ø§Ù„Ø«Ø§Ù†ÙŠØ©

#     # Ø­Ø³Ø§Ø¨ ØªØ´Ø§Ø¨Ù‡ Cosine Ø¨ÙŠÙ† Ø§Ù„ÙˆØ¬Ù‡ÙŠÙ†
#     distance = cosine(embedding1, embedding2)  # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø³Ø§ÙØ© Ø§Ù„ÙƒÙˆØ²ÙŠÙ†ÙŠØ©
#     similarity_insightface = (1 - distance) * 100  # ØªØ­ÙˆÙŠÙ„Ù‡Ø§ Ø¥Ù„Ù‰ Ù†Ø³Ø¨Ø© Ù…Ø¦ÙˆÙŠØ©

# ================== ğŸ“Œ Ø·Ø¨Ø§Ø¹Ø© Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ==================
print("ğŸ” **Ù†ØªØ§Ø¦Ø¬ Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„ÙˆØ¬Ù‡:**")
print(f"âœ… Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ´Ø§Ø¨Ù‡ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… **DeepFace**: {similarity_deepface:.2f}%")
# print(f"âœ… Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ´Ø§Ø¨Ù‡ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… **InsightFace (ArcFace)**: {similarity_insightface:.2f}%")

import os
import pickle
from tqdm import tqdm
from deepface import DeepFace
import numpy as np

# # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ù…Ù† ÙÙˆÙ„Ø¯Ø± ÙˆØªØ®Ø²ÙŠÙ†Ù‡Ø§ ÙÙŠ Ù…Ù„Ù pkl
def extract_features_from_folder(folder_path, output_file):
    feature_dict = {}
    for image_name in tqdm(os.listdir(folder_path), desc="Extracting features"):
        image_path = os.path.join(folder_path, image_name)
        try:
            result = DeepFace.represent(image_path, model_name="VGG-Face", enforce_detection=False)
            # Store only the embedding vector
            feature_dict[image_name] = np.array(result[0]["embedding"])
        except Exception as e:
            print(f"Error processing {image_name}: {e}")

    with open(output_file, 'wb') as f:
        pickle.dump(feature_dict, f)

# Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
folder_path = "/content/data/2"  # Ø§Ø³ØªØ¨Ø¯Ù„Ù‡Ø§ Ø¨Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ø¬Ù„Ø¯
output_file = "/content/features3.pkl"  # Ù…Ù„Ù pkl Ø§Ù„Ø°ÙŠ Ø³ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø§Ù„Ù…ÙŠØ²Ø§Øª

# Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…ÙŠØ²Ø§Øª ÙˆØ­ÙØ¸Ù‡Ø§
extract_features_from_folder(folder_path, output_file)

import cv2
import os
import numpy as np
from google.colab.patches import cv2_imshow  # Ø§Ø³ØªØ®Ø¯Ù… cv2.imshow Ø¥Ø°Ø§ ÙƒÙ†Øª ØªØ¹Ù…Ù„ Ù…Ø­Ù„ÙŠÙ‹Ø§
def compare_image(input_image_path, feature_file, top_n=3):
    with open(feature_file, 'rb') as f:
        feature_dict = pickle.load(f)

    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ÙŠØ²Ø§Øª Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ø¯Ø®Ù„Ø©
    input_feature = DeepFace.represent(input_image_path, model_name="VGG-Face", enforce_detection=False)[0]["embedding"]

    distances = []

    # Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù…ÙŠØ²Ø§Øª ÙˆØ­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø³Ø§ÙØ§Øª
    for image_name, stored_feature in feature_dict.items():
        distance = np.linalg.norm(np.array(input_feature) - np.array(stored_feature))
        distances.append((image_name, distance))

    # ØªØ±ØªÙŠØ¨ Ø§Ù„ØµÙˆØ± Ø­Ø³Ø¨ Ø§Ù„Ù…Ø³Ø§ÙØ©
    distances.sort(key=lambda x: x[1])

    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø£Ù‚Ø±Ø¨ top_n ØµÙˆØ±
    closest_images = distances[:top_n]

    return closest_images
def compare_and_display(input_image_path, feature_file, dataset_path, top_n=3):
    # Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø§Ù„Ø¯Ø§Ù„Ø© Ù„Ø­Ø³Ø§Ø¨ Ø£Ù‚Ø±Ø¨ Ø§Ù„ØµÙˆØ±
    closest_images = compare_image(input_image_path, feature_file, top_n)

    print("ğŸ“¸ Ø£Ù‚Ø±Ø¨ 3 ØµÙˆØ± Ù‡ÙŠ:")

    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ø¯Ø®Ù„Ø©
    input_img = cv2.imread(input_image_path)

    # Ø­Ø³Ø§Ø¨ Ø£Ù‚ØµÙ‰ Ù…Ø³Ø§ÙØ© Ù„ØªØ·Ø¨ÙŠØ¹ Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ´Ø§Ø¨Ù‡
    max_distance = max([dist for _, dist in closest_images]) if closest_images else 1

    for i, (image_name, distance) in enumerate(closest_images):
        # Ø­Ø³Ø§Ø¨ Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ´Ø§Ø¨Ù‡ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø³Ø§ÙØ©
        similarity_deepface = (1 - (distance / max_distance)) * 100 if max_distance > 0 else 100
        similarity_deepface = max(0, min(similarity_deepface, 100))  # Ø§Ù„ØªØ£ÙƒØ¯ Ø£Ù† Ø§Ù„Ù†Ø³Ø¨Ø© Ø¨ÙŠÙ† 0% Ùˆ 100%

        # Ø·Ø¨Ø§Ø¹Ø© Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ´Ø§Ø¨Ù‡
        print(f"ğŸ”¹ Ø§Ù„ØµÙˆØ±Ø© {i+1}: {image_name} | Ø§Ù„Ù…Ø³Ø§ÙØ©: {distance:.4f} | Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ´Ø§Ø¨Ù‡: {similarity_deepface:.2f}%")

        # ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø©
        matched_img_path = os.path.join(dataset_path, image_name)
        matched_img = cv2.imread(matched_img_path)

        if matched_img is not None:
            # Ø¹Ø±Ø¶ Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ´Ø§Ø¨Ù‡ Ø«Ù… Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø©
            print(f"ğŸ”¸ Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ´Ø§Ø¨Ù‡ Ù„Ù„ØµÙˆØ±Ø© {i+1}: {similarity_deepface:.2f}%")
            cv2_imshow(matched_img)  # Ø¹Ø±Ø¶ Ø§Ù„ØµÙˆØ±Ø©
            print("")  # Ø³Ø·Ø± ÙØ§Ø±Øº Ø¨ÙŠÙ† Ø§Ù„ØµÙˆØ± Ù„Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„ÙˆØ¶ÙˆØ­

def display_images(input_img, matched_images):
    """Ø¹Ø±Ø¶ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ø¯Ø®Ù„Ø© Ø¨Ø¬Ø§Ù†Ø¨ Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© Ù…Ø¹ Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ´Ø§Ø¨Ù‡"""
    if not matched_images:
        print("âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ ØµÙˆØ± Ù…ØªØ·Ø§Ø¨Ù‚Ø©!")
        return

    # ØªØºÙŠÙŠØ± Ø­Ø¬Ù… Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ø¯Ø®Ù„Ø© Ù„ØªØªÙ†Ø§Ø³Ø¨ Ù…Ø¹ Ø§Ù„ØµÙˆØ± Ø§Ù„Ø£Ø®Ø±Ù‰
    w = matched_images[0][0].shape[1]  # Ø£Ø®Ø° Ø¹Ø±Ø¶ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰
    h = matched_images[0][0].shape[0]  # Ø£Ø®Ø° Ø§Ø±ØªÙØ§Ø¹ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰
    input_resized = cv2.resize(input_img, (w, h))

    # Ø¯Ù…Ø¬ Ø§Ù„ØµÙˆØ± Ø¹Ù…ÙˆØ¯ÙŠÙ‹Ø§ Ù…Ø¹ ØªØºÙŠÙŠØ± Ø§Ù„Ø­Ø¬Ù… Ù„ØªØªÙ†Ø§Ø³Ø¨ Ù…Ø¹ Ù†ÙØ³ Ø§Ù„Ø¹Ø±Ø¶
    combined_img = [input_resized] + [cv2.resize(img, (w, h)) for img, _ in matched_images]
    final_image = cv2.vconcat(combined_img)  # Ø¯Ù…Ø¬ Ø§Ù„ØµÙˆØ± Ø¹Ù…ÙˆØ¯ÙŠÙ‹Ø§

    # Ø¹Ø±Ø¶ Ø§Ù„ØµÙˆØ± Ø¹Ù…ÙˆØ¯ÙŠÙ‹Ø§
    cv2_imshow(final_image)

    # Ø·Ø¨Ø§Ø¹Ø© Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ´Ø§Ø¨Ù‡ Ø£Ø³ÙÙ„ ÙƒÙ„ ØµÙˆØ±Ø©
    for i, (_, similarity) in enumerate(matched_images):
        print(f"ğŸ”¹ ØµÙˆØ±Ø© {i+1}: Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ´Ø§Ø¨Ù‡ {similarity:.2f}%")

# Ø¨Ø¹Ø¯ Ø±ÙØ¹ ØµÙˆØ±Ø© Ø¬Ø¯ÙŠØ¯Ø©ØŒ ÙŠÙ…ÙƒÙ†Ùƒ Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„ØµÙˆØ±Ø© Ù…Ø¹ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ù…Ø®Ø²Ù†Ø© ÙˆØ§Ø³ØªØ®Ø±Ø§Ø¬ Ø£Ù‚Ø±Ø¨ 3 ØµÙˆØ±
# input_image_path = "/content/gettyimages-1437589921-612x612.jpg"  # Ø§Ø³ØªØ¨Ø¯Ù„Ù‡Ø§ Ø¨Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„ØªÙŠ ØªØ±ØºØ¨ ÙÙŠ Ù…Ù‚Ø§Ø±Ù†ØªÙ‡Ø§
# closest_images = compare_image(input_image_path, output_file)

# print("The closest 3 images are:")
# for image_name, distance in closest_images:
#     print(f"{image_name} with distance: {distance}")
output_file = "/content/features2.pkl"
input_image_path = "/content/photo_2025-01-31_12-02-05.jpg"  # Ø§Ø³ØªØ¨Ø¯Ù„Ù‡Ø§ Ø¨Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ø¯Ø®Ù„Ø©
dataset_path = "/content/data/2"  # Ù…Ø³Ø§Ø± Ø§Ù„Ø¯Ø§ØªØ§ Ø³Øª Ø§Ù„Ø®Ø§ØµØ© Ø¨Ùƒ
compare_and_display(input_image_path, output_file, dataset_path)

#########################################optimize model for extract two images

import pickle

# Load the embeddings file
file_path = "/content/features2.pkl"

def count_vectors(file_path):
    try:
        with open(file_path, "rb") as f:
            embeddings = pickle.load(f)  # Load the embeddings dictionary

        # Count the number of vectors
        vector_count = len(embeddings)
        print(f"Number of vectors in the file: {vector_count}")
    except Exception as e:
        print(f"An error occurred: {e}")

# Call the function
count_vectors(file_path)

# from scipy.spatial.distance import cosine
# import cv2
# from google.colab.patches import cv2_imshow

# dataset_path = "/content/2"
# def compare_face(input_image_path):
#     # ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ø¯Ø®Ù„Ø©
#     input_img = cv2.imread(input_image_path)
#     faces_input = app.get(input_img)

#     if len(faces_input) > 0:
#         input_embedding = faces_input[0].embedding  # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù€ Embedding Ù„Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ø¯Ø®Ù„Ø©

#         best_match = None
#         best_distance = float("inf")

#         # Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù€ Embedding Ø§Ù„Ù…Ø¯Ø®Ù„ Ù…Ø¹ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù€ Embeddings Ø§Ù„Ù…Ø®Ø²Ù†Ø©
#         for filename, stored_embedding in image_embeddings.items():
#             distance = cosine(input_embedding, stored_embedding)

#             if distance < best_distance:
#                 best_distance = distance
#                 best_match = filename

#         # Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ù…Ø³Ø§ÙØ© Ø£Ù‚Ù„ Ù…Ù† Ø­Ø¯ Ù…Ø¹ÙŠÙ† (Ù…Ø«Ù„Ø§Ù‹ 0.6)ØŒ ÙØ¥Ù† Ø§Ù„ÙˆØ¬Ù‡ Ù…ØªØ·Ø§Ø¨Ù‚
#         if best_distance :#< 0.6
#             similarity = (1 - best_distance) * 100  # Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ´Ø§Ø¨Ù‡ (Ø¨Ø§Ù„Ù†Ø³Ø¨Ø© Ø§Ù„Ù…Ø¦ÙˆÙŠØ©)
#             print(f"Ø§Ù„Ø´Ø®Øµ Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Ø§Ù„ØµÙˆØ±Ø©: {best_match} (Ø§Ù„Ù…Ø³Ø§ÙØ©: {best_distance}, Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ´Ø§Ø¨Ù‡: {similarity:.2f}%)")

#             # Ø¹Ø±Ø¶ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© ÙˆØ§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ø¯Ø®Ù„Ø© Ø¬Ù†Ø¨Ù‹Ø§ Ø¥Ù„Ù‰ Ø¬Ù†Ø¨
#             matched_img_path = f"{dataset_path}/{best_match}"
#             matched_img = cv2.imread(matched_img_path)

#             # ØªØºÙŠÙŠØ± Ø­Ø¬Ù… Ø§Ù„ØµÙˆØ± Ù„ØªÙƒÙˆÙ† Ø¨Ù†ÙØ³ Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯
#             input_img = cv2.resize(input_img, (matched_img.shape[1], matched_img.shape[0]))

#             combined_img = cv2.hconcat([input_img, matched_img])

#             # Ø¹Ø±Ø¶ Ø§Ù„ØµÙˆØ± Ø¬Ù†Ø¨Ù‹Ø§ Ø¥Ù„Ù‰ Ø¬Ù†Ø¨
#             cv2_imshow(combined_img)
#             cv2.waitKey(0)
#             cv2.destroyAllWindows()
#         else:
#             print("Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ ØªØ·Ø§Ø¨Ù‚.")
#     else:
#         print("Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ ÙˆØ¬Ù‡ ÙÙŠ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ø¯Ø®Ù„Ø©.")

# # Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø¯Ø§Ù„Ø© Ù…Ø¹ ØµÙˆØ±Ø© Ø¬Ø¯ÙŠØ¯Ø©
# compare_face("/content/436x328_97938_197934.jpg")

import insightface
from insightface.app import FaceAnalysis
import cv2
import numpy as np

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
# Include the 'landmark_3d_68' module during initialization
app = FaceAnalysis(allowed_modules=['detection', 'recognition', 'landmark_3d_68'], nms=0.4)
app.prepare(ctx_id=0)

# ØªØ­Ù…ÙŠÙ„ ØµÙˆØ±Ø© Ø§Ù„ÙˆØ¬Ù‡
image_path = "/content/gettyimages-578551318-612x612.jpg"
img = cv2.imread(image_path)

# Ø§ÙƒØªØ´Ø§Ù Ø§Ù„ÙˆØ¬Ù‡ ÙˆØ§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ø¹Ø§Ù„Ù…
faces = app.get(img)

if len(faces) > 0:
    face = faces[0]

    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ø¹Ø§Ù„Ù… Ø«Ù„Ø§Ø«ÙŠØ© Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯ ÙˆØ«Ù†Ø§Ø¦ÙŠØ© Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯
    landmark_3d = face.landmark_3d_68
    landmark_2d = face.landmark_2d_106

    # Check if landmark_3d is not None before iterating
    if landmark_3d is not None:
        # Ø±Ø³Ù… Ø§Ù„Ù…Ø¹Ø§Ù„Ù… Ø«Ù„Ø§Ø«ÙŠØ© Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯ Ø¨Ø§Ù„Ù„ÙˆÙ† Ø§Ù„Ø£Ø²Ø±Ù‚
        for point in landmark_3d:
            x, y, z = int(point[0]), int(point[1]), point[2]
            cv2.circle(img, (x, y), 2, (255, 0, 0), -1)
    else:
        print("3D Landmarks not detected.")

    # Check if landmark_2d is not None before iterating
    if landmark_2d is not None:
        # Ø±Ø³Ù… Ø¢Ø®Ø± 2 Ù…Ù† Ø§Ù„Ù…Ø¹Ø§Ù„Ù… Ø«Ù†Ø§Ø¦ÙŠØ© Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯ Ø¨Ø§Ù„Ù„ÙˆÙ† Ø§Ù„Ø£Ø®Ø¶Ø±
        for point in landmark_2d[-2:]:
            x, y = int(point[0]), int(point[1])
            cv2.circle(img, (x, y), 3, (0, 255, 0), -1)
    else:
        print("2D Landmarks not detected.")

    # Ø¹Ø±Ø¶ Ø§Ù„ØµÙˆØ±Ø© Ù…Ø¹ Ø§Ù„Ù…Ø¹Ø§Ù„Ù…
    cv2_imshow(img)
    cv2.waitKey(0)
    cv2.destroyAllWindows()

else:
    print("Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ ÙˆØ¬Ù‡ ÙÙŠ Ø§Ù„ØµÙˆØ±Ø©.")

import insightface
from insightface.app import FaceAnalysis
import cv2
import numpy as np
from scipy.spatial.distance import cosine
import os

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ø¹ Ø¯Ø¹Ù… Ø§Ù„Ù…Ø¹Ø§Ù„Ù… Ø«Ù„Ø§Ø«ÙŠØ© Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯
app = FaceAnalysis(allowed_modules=['detection', 'recognition', 'landmark_3d_68'], nms=0.4)
app.prepare(ctx_id=0)  # ctx_id=0 ØªØ¹Ù†ÙŠ Ø§Ø³ØªØ®Ø¯Ø§Ù… GPU Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…ØªÙˆÙØ±Ù‹Ø§

# Ù…Ø³Ø§Ø± Ø§Ù„ØµÙˆØ±
dataset_path = "/content/3"  # Ø¶Ø¹ Ù…Ø³Ø§Ø± Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„ØµÙˆØ± Ù‡Ù†Ø§
image_embeddings = {}

# Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ù…ÙŠØ²Ø§Øª (features) Ù…Ù† Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„ØµÙˆØ±
for filename in os.listdir(dataset_path):
    if filename.endswith(".jpg") or filename.endswith(".png"):
        img_path = os.path.join(dataset_path, filename)
        img = cv2.imread(img_path)
        faces = app.get(img)

        if len(faces) > 0:
            face = faces[0]
            embedding = face.embedding  # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…ÙŠØ²Ø© (feature) Ù„Ù„ÙˆØ¬Ù‡
            landmark_3d = face.landmark_3d_68
            landmark_2d = face.landmark_2d_106

            # Ø­ÙØ¸ Ø§Ù„Ù…ÙŠØ²Ø© ÙˆØ§Ù„Ù…Ø¹Ø§Ù„Ù… Ø¨Ø§Ø³Ù… Ø§Ù„ØµÙˆØ±Ø©
            image_embeddings[filename] = {
                "embedding": embedding,
                "landmark_3d": landmark_3d,
                "landmark_2d": landmark_2d,
            }
print("ØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ù…Ù† Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„ØµÙˆØ±.")

# Ø¯Ø§Ù„Ø© Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ø¯Ø®Ù„Ø©
def compare_face(input_image_path):
    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ø¯Ø®Ù„Ø©
    input_img = cv2.imread(input_image_path)
    faces_input = app.get(input_img)

    if len(faces_input) > 0:
        face_input = faces_input[0]
        input_embedding = face_input.embedding  # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…ÙŠØ²Ø© Ù„Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ø¯Ø®Ù„Ø©
        input_landmark_3d = face_input.landmark_3d_68
        input_landmark_2d = face_input.landmark_2d_106

        best_match = None
        best_distance = float("inf")

        # Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù…ÙŠØ²Ø© Ø§Ù„Ù…Ø¯Ø®Ù„Ø© Ù…Ø¹ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ù…Ø®Ø²Ù†Ø©
        for filename, data in image_embeddings.items():
            stored_embedding = data["embedding"]
            distance = cosine(input_embedding, stored_embedding)  # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø³Ø§ÙØ© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Cosine

            if distance < best_distance:
                best_distance = distance
                best_match = filename

        # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        if best_distance :  # Ø¹ØªØ¨Ø© Ø§Ù„ØªØ´Ø§Ø¨Ù‡
            similarity = (1 - best_distance) * 100  # Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ´Ø§Ø¨Ù‡
            print(f"Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ø¯Ø®Ù„Ø© ØªØ´Ø¨Ù‡ Ø§Ù„ØµÙˆØ±Ø©: {best_match} (Ø§Ù„Ù…Ø³Ø§ÙØ©: {best_distance:.2f}, Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ´Ø§Ø¨Ù‡: {similarity:.2f}%)")

            # Ø¹Ø±Ø¶ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ø¯Ø®Ù„Ø© ÙˆØ§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø©
            matched_img_path = os.path.join(dataset_path, best_match)
            matched_img = cv2.imread(matched_img_path)

            # ØªØºÙŠÙŠØ± Ø­Ø¬Ù… Ø§Ù„ØµÙˆØ± Ù„ØªÙƒÙˆÙ† Ø¨Ù†ÙØ³ Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯
            input_img_resized = cv2.resize(input_img, (matched_img.shape[1], matched_img.shape[0]))
            combined_img = cv2.hconcat([input_img_resized, matched_img])

            # Ø±Ø³Ù… Ø§Ù„Ù…Ø¹Ø§Ù„Ù… Ø«Ù„Ø§Ø«ÙŠØ© Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯ (Ø¨Ø§Ù„Ø£Ø²Ø±Ù‚) ÙˆØ§Ù„Ù…Ø¹Ø§Ù„Ù… Ø«Ù†Ø§Ø¦ÙŠØ© Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯ (Ø¨Ø§Ù„Ø£Ø®Ø¶Ø±)
            if input_landmark_3d is not None:
                for point in input_landmark_3d:
                    x, y, z = int(point[0]), int(point[1]), point[2]
                    cv2.circle(input_img_resized, (x, y), 2, (255, 0, 0), -1)
            if input_landmark_2d is not None:
                for point in input_landmark_2d[-2:]:
                    x, y = int(point[0]), int(point[1])
                    cv2.circle(input_img_resized, (x, y), 3, (0, 255, 0), -1)

            cv2_imshow( combined_img)
            cv2.waitKey(0)
            cv2.destroyAllWindows()
        else:
            print("Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ ØªØ·Ø§Ø¨Ù‚ Ù…Ù†Ø§Ø³Ø¨.")
    else:
        print("Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ ÙˆØ¬Ù‡ ÙÙŠ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ø¯Ø®Ù„Ø©.")

# Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø¯Ø§Ù„Ø© Ù…Ø¹ ØµÙˆØ±Ø© Ø¬Ø¯ÙŠØ¯Ø©
compare_face("/content/gettyimages-578551318-612x612.jpg")  # Ø¶Ø¹ Ù…Ø³Ø§Ø± Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ø¯Ø®Ù„Ø© Ù‡Ù†Ø§